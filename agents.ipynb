{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "InRQiylLDXF5",
        "outputId": "dab80804-eb11-4e4d-fa56-64274a21db5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (0.3.74)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain_google_genai-2.1.9\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "f074f0215d534e23a772757acaca2a45",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from numexpr) (2.0.2)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.74)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.3-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.3-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.6 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.3 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_google_genai\n",
        "!pip install numexpr\n",
        "!pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abNJsWOrDVDV"
      },
      "outputs": [],
      "source": [
        "# agent.py\n",
        "import json\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "import re\n",
        "import numexpr\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import BaseMessage, ToolMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-Wl0OwrDtja"
      },
      "outputs": [],
      "source": [
        "# Knowlwdgebase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "V9yUPbGYDwbX"
      },
      "outputs": [],
      "source": [
        "KB = {\n",
        "    \"DOC-1\": {\n",
        "        \"title\": \"LLUMO AI – Core Value\",\n",
        "        \"text\": \"LLUMO AI is an evaluation-first reliability layer for LLM apps. It focuses on automated scoring, actionable insights, and cost savings via prompt compression—helping teams ship trustworthy AI.\"\n",
        "    },\n",
        "    \"DOC-2\": {\n",
        "        \"title\": \"LLUMO AI – Debugger\",\n",
        "        \"text\": \"LLUMO’s Debugger shows run-level logs, stepwise tool traces, and a flow graph to isolate failure points such as tool selection errors or context mismatch.\"\n",
        "    },\n",
        "    \"DOC-3\": {\n",
        "        \"title\": \"Company Policy – Working Hours\",\n",
        "        \"text\": \"Standard working hours are 10:00 to 18:30 IST, Monday to Friday. Flexible timings are allowed with manager approval.\"\n",
        "    },\n",
        "    \"DOC-4\": {\n",
        "        \"title\": \"Finance FAQ – Reimbursements\",\n",
        "        \"text\": \"Submit reimbursements within 30 days. Keep original receipts. Typical settlement time is 7 business days after approval.\"\n",
        "    },\n",
        "    \"DOC-5\": {\n",
        "        \"title\": \"Math Snippets\",\n",
        "        \"text\": \"Examples: (125 * 6) - 50 = 700; 15% of 640 = 96; Average of [10, 20, 30, 40] = 25.\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glwL7-xxD2Z8"
      },
      "outputs": [],
      "source": [
        "# --- Tool Implementations ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avD-8-QvD8kH"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tool\n",
        "def retriever(query: str, k: int = 1) -> list[str]:\n",
        "    \"\"\"\n",
        "    Loads the Knowledge Base and returns the top-K passages that are most relevant to the query.\n",
        "    This is a general-purpose tool for finding information.\n",
        "    \"\"\"\n",
        "    query_words = set(query.lower().split())\n",
        "    scores = {}\n",
        "    for doc_id, content in KB.items():\n",
        "        doc_words = set(content['title'].lower().split()) | set(content['text'].lower().split())\n",
        "        score = len(query_words.intersection(doc_words))\n",
        "        if score > 0:\n",
        "            scores[doc_id] = score\n",
        "    sorted_docs = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    return [KB[doc_id]['text'] for doc_id, _ in sorted_docs[:k]]\n",
        "\n",
        "@tool\n",
        "def policy_lookup(query: str) -> str:\n",
        "    \"\"\"\n",
        "    A specialized tool to look up information specifically from policy or FAQ documents.\n",
        "    This is a shortcut to the retriever for common internal queries.\n",
        "    \"\"\"\n",
        "    query_words = set(query.lower().split())\n",
        "\n",
        "    policy_docs = {\n",
        "        doc_id: content for doc_id, content in KB.items()\n",
        "        if \"policy\" in content['title'].lower() or \"faq\" in content['title'].lower()\n",
        "    }\n",
        "\n",
        "    scores = {}\n",
        "    for doc_id, content in policy_docs.items():\n",
        "        doc_words = set(content['title'].lower().split()) | set(content['text'].lower().split())\n",
        "        score = len(query_words.intersection(doc_words))\n",
        "        if score > 0:\n",
        "            scores[doc_id] = score\n",
        "\n",
        "    if not scores:\n",
        "        return \"No specific policy or FAQ document found that matches the query.\"\n",
        "\n",
        "    best_doc_id = max(scores, key=scores.get)\n",
        "    return KB[best_doc_id]['text']\n",
        "\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Performs arithmetic calculations safely.\n",
        "    It can handle standard mathematical operations.\n",
        "    For percentages, please convert them to decimals (e.g., 15% of 640 should be input as '0.15 * 640').\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = numexpr.evaluate(expression).item()\n",
        "        return f\"The result of the expression '{expression}' is: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: Could not evaluate the expression. Details: {e}\"\n",
        "\n",
        "@tool\n",
        "def string_tools(text: str, extract: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    A utility tool to extract specific patterns from a given text.\n",
        "    'extract' can be 'numbers' or 'percentages'.\n",
        "    \"\"\"\n",
        "    if extract.lower() == \"numbers\":\n",
        "        return re.findall(r'\\d+\\.\\d+|\\d+', text)\n",
        "    elif extract.lower() == \"percentages\":\n",
        "        return re.findall(r'\\d+\\s*%', text)\n",
        "    else:\n",
        "        return [\"Error: Invalid 'extract' parameter. Please use 'numbers' or 'percentages'.\"]\n",
        "\n",
        "# A list containing all the tools that the agent can use.\n",
        "all_tools = [retriever, policy_lookup, calculator, string_tools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "5J8CITBqEVX3"
      },
      "outputs": [],
      "source": [
        "# --- 1. Define Agent State ---\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], lambda x, y: x + y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "jvStgITCH_ea"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant designed to answer user queries. You MUST use the tools provided to find the information. Do not apologize or say you cannot access information. Use the tools to get the answer.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihj0-B5PEg0h"
      },
      "outputs": [],
      "source": [
        "# model use gemini api 2.0-flash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxegoeXgEksj"
      },
      "outputs": [],
      "source": [
        "api_key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "23SFw4JKEicv"
      },
      "outputs": [],
      "source": [
        "model = ChatGoogleGenerativeAI(temperature=0.3, model=\"gemini-2.0-flash\",api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "DYirTye4E254"
      },
      "outputs": [],
      "source": [
        "model = model.bind_tools(all_tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating chain "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "f8KLKbWuIHW6"
      },
      "outputs": [],
      "source": [
        "agent_runnable = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbozDbS1E8b2"
      },
      "outputs": [],
      "source": [
        "def should_continue(state: AgentState) -> str:\n",
        "    \"\"\"\n",
        "    This is a conditional edge. It determines whether the agent should continue calling tools\n",
        "    or if it's ready to generate the final response.\n",
        "    \"\"\"\n",
        "    last_message = state['messages'][-1]\n",
        "    if not last_message.tool_calls:\n",
        "        return \"end\"\n",
        "    return \"continue\"\n",
        "\n",
        "def call_model(state: AgentState):\n",
        "    \"\"\"\n",
        "    This node is responsible for calling the language model.\n",
        "    \"\"\"\n",
        "    response = agent_runnable.invoke(state)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 4. Build the Graph ---\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"action\", ToolNode(all_tools))\n",
        "\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"continue\": \"action\",\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"action\", \"agent\")\n",
        "\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----Workflow------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "Fh5Bpa3sFDfL",
        "outputId": "b4f3b7c3-407d-4414-d664-bd1d79c934e5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7f70d23a5c40>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 5. Run the Agent Interactively ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeycMEeRDQTm",
        "outputId": "3e3b82f2-26dd-4e9f-c3a6-3d3e6d9b4e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query (or type 'exit' to quit): LLUMO AI – Core Value\n",
            "\n",
            "--- Running Query: LLUMO AI – Core Value ---\n",
            "Step Output: [HumanMessage(content='LLUMO AI – Core Value', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Step Output: [HumanMessage(content='LLUMO AI – Core Value', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"LLUMO AI core values\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--cf38a993-ca22-4506-8f5e-cef30780246d-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'LLUMO AI core values'}, 'id': '33a0ac17-41c2-4d45-a18b-6cde4a5783f2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 214, 'output_tokens': 10, 'total_tokens': 224, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "Step Output: [HumanMessage(content='LLUMO AI – Core Value', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"LLUMO AI core values\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--cf38a993-ca22-4506-8f5e-cef30780246d-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'LLUMO AI core values'}, 'id': '33a0ac17-41c2-4d45-a18b-6cde4a5783f2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 214, 'output_tokens': 10, 'total_tokens': 224, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='No specific policy or FAQ document found that matches the query.', name='policy_lookup', tool_call_id='33a0ac17-41c2-4d45-a18b-6cde4a5783f2')]\n",
            "\n",
            "Step Output: [HumanMessage(content='LLUMO AI – Core Value', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"LLUMO AI core values\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--cf38a993-ca22-4506-8f5e-cef30780246d-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'LLUMO AI core values'}, 'id': '33a0ac17-41c2-4d45-a18b-6cde4a5783f2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 214, 'output_tokens': 10, 'total_tokens': 224, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='No specific policy or FAQ document found that matches the query.', name='policy_lookup', tool_call_id='33a0ac17-41c2-4d45-a18b-6cde4a5783f2'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever', 'arguments': '{\"query\": \"LLUMO AI core values\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--3f9e96d8-0b01-4b2d-818d-315f153da6d1-0', tool_calls=[{'name': 'retriever', 'args': {'query': 'LLUMO AI core values'}, 'id': '6baed7e7-56aa-4b42-b422-6a4c6f1c1d17', 'type': 'tool_call'}], usage_metadata={'input_tokens': 240, 'output_tokens': 9, 'total_tokens': 249, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "Step Output: [HumanMessage(content='LLUMO AI – Core Value', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"LLUMO AI core values\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--cf38a993-ca22-4506-8f5e-cef30780246d-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'LLUMO AI core values'}, 'id': '33a0ac17-41c2-4d45-a18b-6cde4a5783f2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 214, 'output_tokens': 10, 'total_tokens': 224, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='No specific policy or FAQ document found that matches the query.', name='policy_lookup', tool_call_id='33a0ac17-41c2-4d45-a18b-6cde4a5783f2'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever', 'arguments': '{\"query\": \"LLUMO AI core values\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--3f9e96d8-0b01-4b2d-818d-315f153da6d1-0', tool_calls=[{'name': 'retriever', 'args': {'query': 'LLUMO AI core values'}, 'id': '6baed7e7-56aa-4b42-b422-6a4c6f1c1d17', 'type': 'tool_call'}], usage_metadata={'input_tokens': 240, 'output_tokens': 9, 'total_tokens': 249, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[\"LLUMO AI is an evaluation-first reliability layer for LLM apps. It focuses on automated scoring, actionable insights, and cost savings via prompt compression—helping teams ship trustworthy AI.\"]', name='retriever', tool_call_id='6baed7e7-56aa-4b42-b422-6a4c6f1c1d17')]\n",
            "\n",
            "Step Output: [HumanMessage(content='LLUMO AI – Core Value', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"LLUMO AI core values\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--cf38a993-ca22-4506-8f5e-cef30780246d-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'LLUMO AI core values'}, 'id': '33a0ac17-41c2-4d45-a18b-6cde4a5783f2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 214, 'output_tokens': 10, 'total_tokens': 224, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='No specific policy or FAQ document found that matches the query.', name='policy_lookup', tool_call_id='33a0ac17-41c2-4d45-a18b-6cde4a5783f2'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever', 'arguments': '{\"query\": \"LLUMO AI core values\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--3f9e96d8-0b01-4b2d-818d-315f153da6d1-0', tool_calls=[{'name': 'retriever', 'args': {'query': 'LLUMO AI core values'}, 'id': '6baed7e7-56aa-4b42-b422-6a4c6f1c1d17', 'type': 'tool_call'}], usage_metadata={'input_tokens': 240, 'output_tokens': 9, 'total_tokens': 249, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[\"LLUMO AI is an evaluation-first reliability layer for LLM apps. It focuses on automated scoring, actionable insights, and cost savings via prompt compression—helping teams ship trustworthy AI.\"]', name='retriever', tool_call_id='6baed7e7-56aa-4b42-b422-6a4c6f1c1d17'), AIMessage(content='I was not able to find the core values of LLUMO AI. However, I found that LLUMO AI is an evaluation-first reliability layer for LLM apps. It focuses on automated scoring, actionable insights, and cost savings via prompt compression—helping teams ship trustworthy AI.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--a047de96-c896-4db0-86a1-dde423aaf1ea-0', usage_metadata={'input_tokens': 290, 'output_tokens': 58, 'total_tokens': 348, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "\n",
            "Final Answer: I was not able to find the core values of LLUMO AI. However, I found that LLUMO AI is an evaluation-first reliability layer for LLM apps. It focuses on automated scoring, actionable insights, and cost savings via prompt compression—helping teams ship trustworthy AI.\n",
            "\n",
            "Enter your query (or type 'exit' to quit): LLUMO AI – Debugger\n",
            "\n",
            "--- Running Query: LLUMO AI – Debugger ---\n",
            "Step Output: [HumanMessage(content='LLUMO AI – Debugger', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Step Output: [HumanMessage(content='LLUMO AI – Debugger', additional_kwargs={}, response_metadata={}), AIMessage(content='How can I help you with LLUMO AI Debugger?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--e2e757e3-4976-4d4f-a54a-781cef0bd435-0', usage_metadata={'input_tokens': 214, 'output_tokens': 14, 'total_tokens': 228, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "\n",
            "Final Answer: How can I help you with LLUMO AI Debugger?\n",
            "\n",
            "Enter your query (or type 'exit' to quit): tell me about LLUMO AI – Debugger\n",
            "\n",
            "--- Running Query: tell me about LLUMO AI – Debugger ---\n",
            "Step Output: [HumanMessage(content='tell me about LLUMO AI – Debugger', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Step Output: [HumanMessage(content='tell me about LLUMO AI – Debugger', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever', 'arguments': '{\"query\": \"LLUMO AI \\\\u2013 Debugger\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--17da6c41-1b91-4035-9fed-fdd7b0c4aa13-0', tool_calls=[{'name': 'retriever', 'args': {'query': 'LLUMO AI – Debugger'}, 'id': '5c69fcda-dfae-4150-8a34-ce1f2b608ae3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 217, 'output_tokens': 10, 'total_tokens': 227, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "Step Output: [HumanMessage(content='tell me about LLUMO AI – Debugger', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever', 'arguments': '{\"query\": \"LLUMO AI \\\\u2013 Debugger\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--17da6c41-1b91-4035-9fed-fdd7b0c4aa13-0', tool_calls=[{'name': 'retriever', 'args': {'query': 'LLUMO AI – Debugger'}, 'id': '5c69fcda-dfae-4150-8a34-ce1f2b608ae3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 217, 'output_tokens': 10, 'total_tokens': 227, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[\"LLUMO’s Debugger shows run-level logs, stepwise tool traces, and a flow graph to isolate failure points such as tool selection errors or context mismatch.\"]', name='retriever', tool_call_id='5c69fcda-dfae-4150-8a34-ce1f2b608ae3')]\n",
            "\n",
            "Step Output: [HumanMessage(content='tell me about LLUMO AI – Debugger', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever', 'arguments': '{\"query\": \"LLUMO AI \\\\u2013 Debugger\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--17da6c41-1b91-4035-9fed-fdd7b0c4aa13-0', tool_calls=[{'name': 'retriever', 'args': {'query': 'LLUMO AI – Debugger'}, 'id': '5c69fcda-dfae-4150-8a34-ce1f2b608ae3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 217, 'output_tokens': 10, 'total_tokens': 227, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[\"LLUMO’s Debugger shows run-level logs, stepwise tool traces, and a flow graph to isolate failure points such as tool selection errors or context mismatch.\"]', name='retriever', tool_call_id='5c69fcda-dfae-4150-8a34-ce1f2b608ae3'), AIMessage(content=\"LLUMO's Debugger provides run-level logs, stepwise tool traces, and a flow graph to help you identify failure points, such as tool selection errors or context mismatch.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--40159661-348b-4c0e-83a0-b5a58f51e88f-0', usage_metadata={'input_tokens': 264, 'output_tokens': 38, 'total_tokens': 302, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "\n",
            "Final Answer: LLUMO's Debugger provides run-level logs, stepwise tool traces, and a flow graph to help you identify failure points, such as tool selection errors or context mismatch.\n",
            "\n",
            "Enter your query (or type 'exit' to quit): Company Policy – Working Hours\n",
            "\n",
            "--- Running Query: Company Policy – Working Hours ---\n",
            "Step Output: [HumanMessage(content='Company Policy – Working Hours', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Step Output: [HumanMessage(content='Company Policy – Working Hours', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"Working Hours\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--aba0678c-30da-403f-90c0-31556509e10d-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'Working Hours'}, 'id': '69cbc282-fabf-408f-90d2-d84ab147f0e7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 212, 'output_tokens': 6, 'total_tokens': 218, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "Step Output: [HumanMessage(content='Company Policy – Working Hours', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"Working Hours\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--aba0678c-30da-403f-90c0-31556509e10d-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'Working Hours'}, 'id': '69cbc282-fabf-408f-90d2-d84ab147f0e7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 212, 'output_tokens': 6, 'total_tokens': 218, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Standard working hours are 10:00 to 18:30 IST, Monday to Friday. Flexible timings are allowed with manager approval.', name='policy_lookup', tool_call_id='69cbc282-fabf-408f-90d2-d84ab147f0e7')]\n",
            "\n",
            "Step Output: [HumanMessage(content='Company Policy – Working Hours', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"Working Hours\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--aba0678c-30da-403f-90c0-31556509e10d-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'Working Hours'}, 'id': '69cbc282-fabf-408f-90d2-d84ab147f0e7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 212, 'output_tokens': 6, 'total_tokens': 218, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Standard working hours are 10:00 to 18:30 IST, Monday to Friday. Flexible timings are allowed with manager approval.', name='policy_lookup', tool_call_id='69cbc282-fabf-408f-90d2-d84ab147f0e7'), AIMessage(content='Standard working hours are 10:00 to 18:30 IST, Monday to Friday. Flexible timings are allowed with manager approval.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--09322497-bb21-43e3-aef6-8442fce8ffa6-0', usage_metadata={'input_tokens': 253, 'output_tokens': 32, 'total_tokens': 285, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "\n",
            "Final Answer: Standard working hours are 10:00 to 18:30 IST, Monday to Friday. Flexible timings are allowed with manager approval.\n",
            "\n",
            "Enter your query (or type 'exit' to quit): Finance FAQ – Reimbursements\n",
            "\n",
            "--- Running Query: Finance FAQ – Reimbursements ---\n",
            "Step Output: [HumanMessage(content='Finance FAQ – Reimbursements', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Step Output: [HumanMessage(content='Finance FAQ – Reimbursements', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"Reimbursements\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--09e2cf7a-8c26-4173-a875-074aa6ad6eec-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'Reimbursements'}, 'id': 'e28b8629-f187-446b-937f-976822b492dd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 213, 'output_tokens': 7, 'total_tokens': 220, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "Step Output: [HumanMessage(content='Finance FAQ – Reimbursements', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"Reimbursements\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--09e2cf7a-8c26-4173-a875-074aa6ad6eec-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'Reimbursements'}, 'id': 'e28b8629-f187-446b-937f-976822b492dd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 213, 'output_tokens': 7, 'total_tokens': 220, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Submit reimbursements within 30 days. Keep original receipts. Typical settlement time is 7 business days after approval.', name='policy_lookup', tool_call_id='e28b8629-f187-446b-937f-976822b492dd')]\n",
            "\n",
            "Step Output: [HumanMessage(content='Finance FAQ – Reimbursements', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'policy_lookup', 'arguments': '{\"query\": \"Reimbursements\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--09e2cf7a-8c26-4173-a875-074aa6ad6eec-0', tool_calls=[{'name': 'policy_lookup', 'args': {'query': 'Reimbursements'}, 'id': 'e28b8629-f187-446b-937f-976822b492dd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 213, 'output_tokens': 7, 'total_tokens': 220, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Submit reimbursements within 30 days. Keep original receipts. Typical settlement time is 7 business days after approval.', name='policy_lookup', tool_call_id='e28b8629-f187-446b-937f-976822b492dd'), AIMessage(content='Reimbursements should be submitted within 30 days, and you should keep the original receipts. The typical settlement time is 7 business days after approval.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--9aa42781-923e-49e6-b46d-40ef1326b31c-0', usage_metadata={'input_tokens': 248, 'output_tokens': 33, 'total_tokens': 281, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "\n",
            "Final Answer: Reimbursements should be submitted within 30 days, and you should keep the original receipts. The typical settlement time is 7 business days after approval.\n",
            "\n",
            "Enter your query (or type 'exit' to quit): solve the 15% of 640\n",
            "\n",
            "--- Running Query: solve the 15% of 640 ---\n",
            "Step Output: [HumanMessage(content='solve the 15% of 640', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Step Output: [HumanMessage(content='solve the 15% of 640', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"0.15 * 640\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--c28e0a58-9e95-4492-8061-b08f836045d2-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '0.15 * 640'}, 'id': '2b71813a-dd95-403c-b58b-35d7cbc887d5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 218, 'output_tokens': 11, 'total_tokens': 229, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "Step Output: [HumanMessage(content='solve the 15% of 640', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"0.15 * 640\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--c28e0a58-9e95-4492-8061-b08f836045d2-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '0.15 * 640'}, 'id': '2b71813a-dd95-403c-b58b-35d7cbc887d5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 218, 'output_tokens': 11, 'total_tokens': 229, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=\"The result of the expression '0.15 * 640' is: 96.0\", name='calculator', tool_call_id='2b71813a-dd95-403c-b58b-35d7cbc887d5')]\n",
            "\n",
            "Step Output: [HumanMessage(content='solve the 15% of 640', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"0.15 * 640\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--c28e0a58-9e95-4492-8061-b08f836045d2-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '0.15 * 640'}, 'id': '2b71813a-dd95-403c-b58b-35d7cbc887d5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 218, 'output_tokens': 11, 'total_tokens': 229, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=\"The result of the expression '0.15 * 640' is: 96.0\", name='calculator', tool_call_id='2b71813a-dd95-403c-b58b-35d7cbc887d5'), AIMessage(content='15% of 640 is 96.0.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--516d9dcb-8aeb-40f4-b58b-36d50f3deccf-0', usage_metadata={'input_tokens': 254, 'output_tokens': 16, 'total_tokens': 270, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "\n",
            "Final Answer: 15% of 640 is 96.0.\n",
            "\n",
            "Enter your query (or type 'exit' to quit): 125*6 - 50\n",
            "\n",
            "--- Running Query: 125*6 - 50 ---\n",
            "Step Output: [HumanMessage(content='125*6 - 50', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Step Output: [HumanMessage(content='125*6 - 50', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"125*6 - 50\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--37c19e40-3d7b-462c-a217-82e083128c27-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '125*6 - 50'}, 'id': '074ce3ef-b8c4-4b9d-885e-d89af80ff11e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 216, 'output_tokens': 11, 'total_tokens': 227, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "Step Output: [HumanMessage(content='125*6 - 50', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"125*6 - 50\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--37c19e40-3d7b-462c-a217-82e083128c27-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '125*6 - 50'}, 'id': '074ce3ef-b8c4-4b9d-885e-d89af80ff11e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 216, 'output_tokens': 11, 'total_tokens': 227, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=\"The result of the expression '125*6 - 50' is: 700\", name='calculator', tool_call_id='074ce3ef-b8c4-4b9d-885e-d89af80ff11e')]\n",
            "\n",
            "Step Output: [HumanMessage(content='125*6 - 50', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"125*6 - 50\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--37c19e40-3d7b-462c-a217-82e083128c27-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '125*6 - 50'}, 'id': '074ce3ef-b8c4-4b9d-885e-d89af80ff11e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 216, 'output_tokens': 11, 'total_tokens': 227, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=\"The result of the expression '125*6 - 50' is: 700\", name='calculator', tool_call_id='074ce3ef-b8c4-4b9d-885e-d89af80ff11e'), AIMessage(content='700', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--82edc035-357d-405d-8bd7-363be3c0d507-0', usage_metadata={'input_tokens': 251, 'output_tokens': 4, 'total_tokens': 255, 'input_token_details': {'cache_read': 0}})]\n",
            "\n",
            "\n",
            "Final Answer: 700\n",
            "\n",
            "Enter your query (or type 'exit' to quit): exit\n",
            "\n",
            "--- Session ended. Logs saved to logs.json ---\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # --- MODIFIED: Switched to an interactive loop instead of a fixed list ---\n",
        "    while True:\n",
        "        query = input(\"Enter your query (or type 'exit' to quit): \")\n",
        "        if query.lower() in [\"exit\", \"quit\"]:\n",
        "            break\n",
        "\n",
        "        print(f\"\\n--- Running Query: {query} ---\")\n",
        "\n",
        "        inputs = {\"messages\": [HumanMessage(content=query)]}\n",
        "\n",
        "        query_log = []\n",
        "\n",
        "        for output in app.stream(inputs, stream_mode=\"values\"):\n",
        "            step_messages = output['messages']\n",
        "            query_log.append(step_messages)\n",
        "            print(f\"Step Output: {step_messages}\\n\")\n",
        "\n",
        "        final_answer = query_log[-1][-1].content\n",
        "        print(f\"\\nFinal Answer: {final_answer}\\n\")\n",
        "\n",
        "        # --- MODIFIED: Append logs to the file instead of overwriting ---\n",
        "        try:\n",
        "            with open(\"logs.json\", \"r+\") as f:\n",
        "                all_logs = json.load(f)\n",
        "        except (FileNotFoundError, json.JSONDecodeError):\n",
        "            all_logs = {}\n",
        "\n",
        "        all_logs[query] = query_log\n",
        "\n",
        "        with open(\"logs.json\", \"w\") as f:\n",
        "            def custom_serializer(o):\n",
        "                if hasattr(o, '__dict__'):\n",
        "                    return o.__dict__\n",
        "                return str(o)\n",
        "            json.dump(all_logs, f, indent=4, default=custom_serializer)\n",
        "\n",
        "    print(\"\\n--- Session ended. Logs saved to logs.json ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI0SJhq_Iqs2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
